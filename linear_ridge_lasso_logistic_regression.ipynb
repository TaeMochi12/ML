{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Linear Regression, Ridge and Lasso**\n",
    "\n",
    "Whichever will give better result, will use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# house pricing dataset\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\himan\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "df=load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[6.3200e-03, 1.8000e+01, 2.3100e+00, ..., 1.5300e+01, 3.9690e+02,\n",
       "         4.9800e+00],\n",
       "        [2.7310e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9690e+02,\n",
       "         9.1400e+00],\n",
       "        [2.7290e-02, 0.0000e+00, 7.0700e+00, ..., 1.7800e+01, 3.9283e+02,\n",
       "         4.0300e+00],\n",
       "        ...,\n",
       "        [6.0760e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         5.6400e+00],\n",
       "        [1.0959e-01, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9345e+02,\n",
       "         6.4800e+00],\n",
       "        [4.7410e-02, 0.0000e+00, 1.1930e+01, ..., 2.1000e+01, 3.9690e+02,\n",
       "         7.8800e+00]]),\n",
       " 'target': array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "        18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "        15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "        13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "        21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "        35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "        19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "        20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "        23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "        33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "        21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "        20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "        23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "        15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "        17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "        25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "        23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "        32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "        34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "        20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "        26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "        31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "        22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "        42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "        36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "        32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "        20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "        20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "        22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "        21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "        19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "        32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "        18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "        16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "        13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "         7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "        12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "        27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "         8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "         9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "        10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "        15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "        19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "        29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "        20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "        23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9]),\n",
       " 'feature_names': array(['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "        'TAX', 'PTRATIO', 'B', 'LSTAT'], dtype='<U7'),\n",
       " 'DESCR': \".. _boston_dataset:\\n\\nBoston house prices dataset\\n---------------------------\\n\\n**Data Set Characteristics:**  \\n\\n    :Number of Instances: 506 \\n\\n    :Number of Attributes: 13 numeric/categorical predictive. Median Value (attribute 14) is usually the target.\\n\\n    :Attribute Information (in order):\\n        - CRIM     per capita crime rate by town\\n        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\\n        - INDUS    proportion of non-retail business acres per town\\n        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\\n        - NOX      nitric oxides concentration (parts per 10 million)\\n        - RM       average number of rooms per dwelling\\n        - AGE      proportion of owner-occupied units built prior to 1940\\n        - DIS      weighted distances to five Boston employment centres\\n        - RAD      index of accessibility to radial highways\\n        - TAX      full-value property-tax rate per $10,000\\n        - PTRATIO  pupil-teacher ratio by town\\n        - B        1000(Bk - 0.63)^2 where Bk is the proportion of black people by town\\n        - LSTAT    % lower status of the population\\n        - MEDV     Median value of owner-occupied homes in $1000's\\n\\n    :Missing Attribute Values: None\\n\\n    :Creator: Harrison, D. and Rubinfeld, D.L.\\n\\nThis is a copy of UCI ML housing dataset.\\nhttps://archive.ics.uci.edu/ml/machine-learning-databases/housing/\\n\\n\\nThis dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\\n\\nThe Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\\nprices and the demand for clean air', J. Environ. Economics & Management,\\nvol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\\n...', Wiley, 1980.   N.B. Various transformations are used in the table on\\npages 244-261 of the latter.\\n\\nThe Boston house-price data has been used in many machine learning papers that address regression\\nproblems.   \\n     \\n.. topic:: References\\n\\n   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\\n   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\\n\",\n",
       " 'filename': 'boston_house_prices.csv',\n",
       " 'data_module': 'sklearn.datasets.data'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0     1     2    3      4      5     6       7    8      9     10  \\\n",
      "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
      "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
      "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
      "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
      "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
      "\n",
      "       11    12  \n",
      "0  396.90  4.98  \n",
      "1  396.90  9.14  \n",
      "2  392.83  4.03  \n",
      "3  394.63  2.94  \n",
      "4  396.90  5.33  \n"
     ]
    }
   ],
   "source": [
    "dataset=pd.DataFrame(df.data)\n",
    "print(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns=df.feature_names\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"Price\"]=df.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=dataset.iloc[:,:-1]  #independent features\n",
    "y=dataset.iloc[:,-1]    # dependent feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Linear Regression\n",
    "> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.18787473928509"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg=LinearRegression()\n",
    "lin_reg.fit(X_train,y_train)\n",
    "mse=cross_val_score(lin_reg,X_train,y_train,scoring='neg_mean_squared_error',cv=5)\n",
    "mean_mse=np.mean(mse)\n",
    "mean_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.001, 0.01, 1, 5, 10,\n",
       "                                   20]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "ridge=Ridge()\n",
    "\n",
    "params={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20]}\n",
    "\n",
    "ridge_regressor=GridSearchCV(ridge,params,scoring='neg_mean_squared_error',cv=5)\n",
    "ridge_regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n",
      "-25.186899367386975\n"
     ]
    }
   ],
   "source": [
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ### Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\himan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.357e+03, tolerance: 2.284e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\himan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.949e+03, tolerance: 2.493e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\himan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.581e+03, tolerance: 2.160e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\himan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.064e+03, tolerance: 2.515e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\himan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.646e+03, tolerance: 2.495e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\himan\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.243e+03, tolerance: 2.988e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Lasso(),\n",
       "             param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.001, 0.01, 1, 5, 10,\n",
       "                                   20]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "lasso=Lasso()\n",
    "\n",
    "params={'alpha':[1e-15,1e-10,1e-8,1e-3,1e-2,1,5,10,20]}\n",
    "\n",
    "lasso_regressor=GridSearchCV(lasso,params,scoring='neg_mean_squared_error',cv=5)\n",
    "lasso_regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1e-15}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_regressor.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-25.187874739285025"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_regressor.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=lin_reg.predict(X_test)\n",
    "y_pred_lasso=lasso_regressor.predict(X_test)\n",
    "y_pred_ridge=ridge_regressor.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score1=r2_score(y_pred,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6709558976744411"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 584x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(y_test,y_pred_lasso);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=load_breast_cancer()\n",
    "# Independent features\n",
    "X=pd.DataFrame(df['data'],columns=df['feature_names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Target\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "..      ...\n",
       "564       0\n",
       "565       0\n",
       "566       0\n",
       "567       0\n",
       "568       1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dependent Feature\n",
    "y=pd.DataFrame(df['target'],columns=['Target'])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y,test_size=0.33,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
